Thursday 23.09

\item [optional] a second source of heterogeneity - speed limits

\item low heterogeneity leads to limited generalization (to other cities in case of topology or to other conditions in case of disruptions or speed limits)
\item increase explainability of ML by comparing their state-action mapping to analytic's. Can be done using clustering and pca, compare action clusters, their centrality measures and variance. What is the difference between hybrid and analytic? 
\end{itemize}

raise:
- we do a good job
- during evaluation it was clear that there is dissatisfaction 
- new departmental head - the issue has been brought to him by student reps but if we make a move as a group we can increase chances of success 
- other departments pay much higher for the same job, cs for example gets rate 5
- the department has not raised salary for phd since 2014 
- covid creates unsafe environment and this can be alleviated with financial well-being
- we would be more attractive when recruiting 


Wed 22.09
python traffic_sim.py --sim_config '../scenarios/ny196/2.config'  1800  1    233.08s user 4.33s system 109% cpu 3:37.73 total




Mon 20

Todo:
- hybrid = hybrid without %
- learning = learning
- learning(1) = learning without %

Times for ny196:
	         training	test
- hybrid         16776		149
- pt hybrid      2460		119
- presslight     13404		107
- pt presslight  2110		105
- analytic  	   -		269


- repeat ablution?
	1. hybrid without %
	2. learning without %
	3. learning

Sun 19.09

Notes:
- seems the hybrid 4x4_1 does not give such good meta results as before: potential reasons: random/bug/saving time model instead of travel
- use state_action analyser to probe state action space of the old and new 4x4base model
- learning models might be misled by the initial steps where there are no cars and rewards are very high?
-where is the randomness coming from?

Sat 18.09

idea:
- compare the roadnetworks and flows and calculate the difference between the scenarios, answer why the training on 4x4 works well, when does it not work well? is it possible to design/generate a scenario that is a good meta-representation. is there a simplification for the network/flow that will adapt the network to a particular more complicated scenario. 

analytic algo time: python traffic_sim.py --sim_config '../scenarios/ny196/2.config'  1800  1    222.65s user 3.94s system 110% cpu 3:25.43 total

roadnet road length values:
- 4x4: 300 100
- 4x4mount: 447.2324105292238 115.82184567734983
- ny16: 397.4204862853793 133.00501446428328
- ny196: 425.78814436740595 108.71689822158706


Friday 17.09


TODO:
- make hybrid faster by optimising arrival and departure rates
- upgrade analytic so that it never sends more cars than capacity 
- ablation study and table
- runtimes and trade off figure - train time against travel time
- run ablation and pretrained on cluster to get training/run times



Thursday 16.09

Notes:
we present best throughput and best travel time which might not always be in the same model :(((

TODO:
- roadnet from points in latex
- upgrade analytic so that it never sends more cars than capacity 
 - ablation study and table
- runtimes and trade off figure - train time against travel time
- get data regarding road lengths for each scenario as well as flows

Monday 13.09
258 x 414
52413
Notes:
- interestingly the model does not seem to work that well on normal roadnets... except for ny196 where it rocks
- scenarios: ny196, ny16, hangzhou, jinan? 
- perhaps it is worth it to compare runtimes of analytic vs hybrid vs pretrained on ny196 (green)
- synthetic ones showcase the result better than cities, unless we use 10 last episodes


TODO:
- check the meta results and generate them using avg or just config1
- the meta results look very good, include the fact that presslight does not adapt well, while learning is better but hybrid is king
- also the best base model appears to be 4x4config1, why?
- upgrade analytic so that it never sends more cars than capacity 
- it might be good to say we train on synthetic and test on real life so instead of 4x4 for testing have one of the cities 


Friday 10.09

Notes:
- use 1800, because ml is visibly better with 3600 xD
- using variable green times does not appear to be helpful for ml
- it seems like models trained on 3600 sim do not translate well to 1800, this can be useful

Thursday 9.09

Pre-process state with pca?

1. run the experiments as outlined, get results, draft paper
Project 3??:
[2. build the action clustering feature and visualise using pca]
[3. build imagination rollout based on the model of traffic]
4. let the paper focus on inability to generalise, perhaps try to improve with adaptive exploration, list experiments

Start with one scenario, take 4x4_config1
1. run presslight/learning/hybrid (start with just one = hybrid) on 4x4_config1
2. save the model
3. run the model on 4x4_mount_config1 (consider also flow_m)

4. turns out the results are good and pretraining with 4x4config1 increases results
5. play around with averaging configs1-4, tho 1 seems to work best
6. the conclusion is ml is not much better than analytic when trained on given scenario but with proper pre-training hybrid is superior and shows meta-learning

7. perhaps use pca analysis of memory replay to explain the quality of the model

8. ablation study removing %state description and analytic exploration


[4. the results should be underwhelming, experiment with adaptive exploration
5. check how many "normal" rounds of training are needed
6. compare to analytic 
7. if this is not promising, use last ten epochs instead of max]
Also: compare [analytic - analytic mount] VS [hybrid - hybrid mount]




Notes:
- 4x4mount() = 3600, (1)=1800, 4x4()=3600, (1)=1800
- ny196(2) = 1800, time=10, (3) = 3600, time=10, (4) = 1800, time=var, (5) = 3600, time=var
- seems like 3600 is better, check with ny196 (0) - 3600 with green_time, (1) - 1800 with green_time, (2) - 3600 green_time=10, (3) - 1800 green_time=10



Wednesday 8.09

1. run hybrid for 3600 and compare
2. Before running the experiments outlined, decide on:
- 1800 vs 3600
- disruption level 1 or 2: 2
- [weather to disrupt flows, can be decided later]

Notes:
- 4x4mount_config1_hybrid() - 3600, hybrid algorithm with agent.green_time = max(5, int(np.max([agent.movements[x].green_time for x in agent.action.movements])))
- 4x4mount (0) = 1800, (1) = 3600, 4x4normal (0) = 1800, (1) = 3600
- 4x4mount 1/2 run with disrupted flow and network (m_m_m) 1800/3600
- 4x4mount config 1 (3), rest (), network 3m, uniform flow, 3600



Tuesday 7.09


FINDINGS:
- (self_pressure + np.mean(neighbour_pressure)) / 2 appears to have some merit... but does not show good results for ny196...
- shared movements neighbour pressure added to individual pressure and averaged leads to worse results than just individual 
- pressure version with just the neighbour shared movements pressure and no individual pressure included does not work
- gpu is a bit faster, use it!!! -R "rusage[ngpus_excl_p=1]"

Notes:
- ny196 with neighbour pressure (new version with just the shared movements)
- ny196(2) - regular pressure ny196(3) - (self_pressure + np.mean(neighbour_pressure)) / 2
- 4x4 with just neighbour pressure () no number
- 4x4 * 4 with old pressure, no neighbours




Monday 6.09

Notes:
- the ny196 run is based on (np.mean(neighbour_pressure) + self.pressure) / 2 with the old version of neighbour pressure
- new version of neighbour pressure uses only the movements which are shared (3 movements) with the target intersection, thus intersections with larger number of neighbours or with more central neighbours will have higher pressure, this might be a problem
- the 4x4 run is testing the above implementation (the names with no number) 


1. figure out euler 
2. run experiments with disrupted topology (neighbour reward) 
3. [run experiments with disrupted speed]
4. combine accordingly
[optional]: if sachit is in, talk about sensors + visualise 


project 2:


1. add neighbour based reward == ability to get pressure of one hop neighbours

mean(neighbour pressure + self.pressure) appears to work for the irregular flows but not for flows with homogenous speed

something is fucked up with grids for 4x4, check it


single author:
- analytical approach with stabilisation is better than ml+alpha-ML
- use dynamic environment 
- generalise settings to more realistic street-nets
- intersections with bi-directionality but different lengths of streets - irregular grids, not needed 3 or 5 lane intersections but maybe worth it


- why ml worse? not considering incoming lanes length, %ML might be better
- ml on non-manhattan grids is comparable to analytic which is much less energy hungry

analytic is truly decentralised, ml is not

Limitation of the analytical approach is that on very short lanes the time needed to cross the lane is short and so the rate of arrivals must be extrapolated and might be inaccurate 


scenarios:
- 4x4 & ny196
compared to:
- mountainous 4x4 
- mountainous ny196

What if we use fundamental diagram in machine learning. 

We can compute the network's average flow as a function of density for the network but can we do it for an intersection, probably yes.

"MFD proposed by Amb ̈uhl et al. (2018) that captures in particular the gap between
the a priori known uMFD and the observed MFD with just a single parameter, λ0. This parameter can
be seen as a quantification of network homogeneity or the between-vehicle interactions"



with Dirk:
- add more irregularity by assuming accidents, variable flows, disruptions 
- non-constant irregularities 


look at neighbours, further than one intersection, groups of intersections 
be good to the neighbour 
highlight why this emergent coordination is good 
food supply chains, perishables, food supply chains 

